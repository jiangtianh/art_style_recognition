{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7bc6408",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b5f045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from neuralart.data import get_chan_data, create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcab6940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78746, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the folder containing Chan's csv files (ie. wikiart_csv)\n",
    "chan_csv_folder_path = \"../raw_data/wikiart/csv_chan\"\n",
    "# Path to the folder containing Chan's images from wikiart (ie. wikiart)\n",
    "chan_image_folder_path = \"../raw_data/wikiart/dataset_chan\"\n",
    "# Path to save a new csv file containing all the information about Chan's dataset\n",
    "csv_output_path = \"../raw_data/wikiart\"\n",
    "\n",
    "chan_data = get_chan_data(chan_csv_folder_path, \n",
    "                          chan_image_folder_path, \n",
    "                          csv_output_path=csv_output_path)\n",
    "chan_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69c414e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 images copied\n",
      "5000 images copied\n",
      "7500 images copied\n",
      "10000 images copied\n",
      "12500 images copied\n",
      "15000 images copied\n",
      "17500 images copied\n",
      "20000 images copied\n",
      "22500 images copied\n",
      "25000 images copied\n",
      "27500 images copied\n",
      "30000 images copied\n",
      "32500 images copied\n",
      "35000 images copied\n",
      "37500 images copied\n",
      "40000 images copied\n",
      "42500 images copied\n",
      "45000 images copied\n",
      "47500 images copied\n",
      "50000 images copied\n",
      "52500 images copied\n",
      "55000 images copied\n",
      "57500 images copied\n",
      "Done: 58714 image(s) copied\n"
     ]
    }
   ],
   "source": [
    "# Dictionary used to merge or drop some classes\n",
    "merge={'name': 'style_m1',\n",
    "       'merging':{'abstract_expressionism': 'abstract', 'action_painting': 'abstract', \n",
    "                  'analytical_cubism': 'cubism', 'art_nouveau_modern': \"baroque\", 'baroque': \"baroque\", \n",
    "                  'color_field_painting': 'color_field_painting', 'contemporary_realism': \"realism\", \n",
    "                  'cubism': 'cubism', 'early_renaissance': 'renaissance', \n",
    "                  'expressionism': 'expressionism', 'fauvism': \"fauvism\", 'high_renaissance': 'renaissance', \n",
    "                  'impressionism': 'impressionism', 'mannerism_late_renaissance': \"renaissance\", \n",
    "                  'minimalism': \"minimalism\", 'naive_art_primitivism': None, 'new_realism': \"realism\", \n",
    "                  'northern_renaissance': 'renaissance', 'pointillism': \"pointillism\", 'pop_art': \"pop\",\n",
    "                  'post_impressionism': \"impressionism\", 'realism': 'realism', 'rococo': \"renaissance\", \n",
    "                  'romanticism': 'romanticism', 'symbolism': None, 'synthetic_cubism': 'cubism', \n",
    "                  'ukiyo_e': \"ukiyo\"}}\n",
    "\n",
    "# Path to save a new csv file containing all the information about the new dataset\n",
    "csv_file_name =  \"../raw_data/wikiart/wikiart-target_style-class_27.csv\"\n",
    "# Path to create a new directory containing all the wikiart images used in the new dataset\n",
    "image_folder_output_path = \"../raw_data/wikiart\"\n",
    "\n",
    "# Image folder structure\n",
    "# Use flat=False if you plan to use the tf.keras.preprocessing.image_dataset_from_directory() function or \n",
    "# the create_dataset_from_directory() function from the trainer module to create the TensorFlow dataset\n",
    "flat=False\n",
    "# Use flat=True if you plan to use the tf.data.Dataset.from_tensor_slices() function or \n",
    "# the create_dataset_from_csv() function from the trainer module to create the TensorFlow dataset\n",
    "#flat=True \n",
    "\n",
    "# Train, Val, and test ratio to split the new dataset\n",
    "val_ratio=0.1\n",
    "test_ratio=0.1\n",
    "\n",
    "data=create_dataset(csv_file_name, \n",
    "                    merge=merge, \n",
    "                    random_state=123,\n",
    "                    chan_image_folder_path=chan_image_folder_path, \n",
    "                    csv_output_path=csv_output_path, \n",
    "                    image_folder_output_path=image_folder_output_path,\n",
    "                    val_ratio=val_ratio,\n",
    "                    test_ratio=test_ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
