{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46971 files belonging to 14 classes.\n",
      "Found 5871 files belonging to 14 classes.\n",
      "Found 5872 files belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, applications\n",
    "\n",
    "# Note : we are using TensorFlow Core v2.5.0, in TensorFlow Core v2.6.0 all the data \n",
    "# augmentation layers are part of tf.keras.layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomZoom\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "\n",
    "TRAIN_DIR = \"../raw_data/wikiart/wikiart-target_style-class_14-keepgenre_True-merge_style_m1-flat_False/train\"\n",
    "VAL_DIR = \"../raw_data/wikiart/wikiart-target_style-class_14-keepgenre_True-merge_style_m1-flat_False/val\"\n",
    "TEST_DIR = \"../raw_data/wikiart/wikiart-target_style-class_14-keepgenre_True-merge_style_m1-flat_False/test\"\n",
    "\n",
    "BATCH_SIZE = 128 # Hyper param, you can tune it\n",
    "EPOCHS = 1000 # Large number, early stopping to stop training before this number\n",
    "IMG_HEIGHT = 224 # VGG's dim\n",
    "IMG_WIDTH = 224 # VGG's dim\n",
    "NUM_CLASSES = 14 # Number of art styles\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=TRAIN_DIR,\n",
    "    labels='inferred',\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "assert len(train_ds.class_names) == NUM_CLASSES\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=VAL_DIR,\n",
    "    labels='inferred',\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "assert len(val_ds.class_names) == NUM_CLASSES\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=TEST_DIR,\n",
    "    labels='inferred',\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "assert len(test_ds.class_names) == NUM_CLASSES\n",
    "\n",
    "total_images_count = (int(len(list(train_ds)))+int(len(list(val_ds)))+int(len(list(test_ds))))*BATCH_SIZE\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Optimizing the dataset by caching and prefetching the data\n",
    "train_ds = train_ds.cache().shuffle(int(total_images_count)).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = applications.VGG16(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data augmentation layers to your model\n",
    "data_augmentation = Sequential([\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomRotation(0.1),\n",
    "    RandomZoom(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the art style recognition model\n",
    "inputs = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(factor=0.2, patience=5),\n",
    "    ModelCheckpoint(\"art_style_recognition_model.h5\", save_best_only=True),\n",
    "    TensorBoard(log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 12:37:52.379671: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 16 of 58752\n",
      "2023-10-24 12:38:02.480890: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 38 of 58752\n",
      "2023-10-24 12:38:12.343766: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 59 of 58752\n",
      "2023-10-24 12:38:22.784012: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 79 of 58752\n",
      "2023-10-24 12:38:32.442338: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 99 of 58752\n",
      "2023-10-24 12:38:42.351415: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 118 of 58752\n",
      "2023-10-24 12:38:52.200619: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 139 of 58752\n",
      "2023-10-24 12:39:02.526601: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 160 of 58752\n",
      "2023-10-24 12:39:13.067525: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 181 of 58752\n",
      "2023-10-24 12:39:22.397633: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 200 of 58752\n",
      "2023-10-24 12:39:32.198604: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 221 of 58752\n",
      "2023-10-24 12:39:42.992020: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 243 of 58752\n",
      "2023-10-24 12:39:52.557103: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 261 of 58752\n",
      "2023-10-24 12:40:02.803543: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 281 of 58752\n",
      "2023-10-24 12:40:12.295165: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 300 of 58752\n",
      "2023-10-24 12:40:22.611418: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 321 of 58752\n",
      "2023-10-24 12:40:32.308120: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 341 of 58752\n",
      "2023-10-24 12:40:42.548080: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 359 of 58752\n",
      "2023-10-24 12:40:42.789908: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 5189s 14s/step - loss: 1.7298 - accuracy: 0.4579 - val_loss: 1.5419 - val_accuracy: 0.5004 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangtianhan/Desktop/You will get good one day/TheUltimateAi/notebook/.venv/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 5078s 14s/step - loss: 1.3447 - accuracy: 0.5294 - val_loss: 1.3932 - val_accuracy: 0.5190 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "367/367 [==============================] - 5023s 14s/step - loss: 1.2529 - accuracy: 0.5595 - val_loss: 1.3421 - val_accuracy: 0.5445 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "367/367 [==============================] - 5109s 14s/step - loss: 1.1903 - accuracy: 0.5759 - val_loss: 1.3801 - val_accuracy: 0.5227 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "367/367 [==============================] - 5136s 14s/step - loss: 1.1384 - accuracy: 0.5958 - val_loss: 1.3380 - val_accuracy: 0.5403 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "367/367 [==============================] - 5100s 14s/step - loss: 1.0896 - accuracy: 0.6108 - val_loss: 1.3115 - val_accuracy: 0.5468 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "367/367 [==============================] - 5028s 14s/step - loss: 1.0556 - accuracy: 0.6206 - val_loss: 1.2853 - val_accuracy: 0.5502 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "367/367 [==============================] - 5039s 14s/step - loss: 1.0156 - accuracy: 0.6336 - val_loss: 1.2558 - val_accuracy: 0.5749 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "367/367 [==============================] - 5048s 14s/step - loss: 0.9858 - accuracy: 0.6444 - val_loss: 1.2991 - val_accuracy: 0.5595 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "367/367 [==============================] - 4946s 13s/step - loss: 0.9521 - accuracy: 0.6584 - val_loss: 1.2519 - val_accuracy: 0.5699 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "367/367 [==============================] - 4925s 13s/step - loss: 0.9248 - accuracy: 0.6689 - val_loss: 1.2876 - val_accuracy: 0.5713 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "367/367 [==============================] - 4913s 13s/step - loss: 0.8969 - accuracy: 0.6772 - val_loss: 1.2787 - val_accuracy: 0.5764 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "367/367 [==============================] - 4921s 13s/step - loss: 0.8739 - accuracy: 0.6881 - val_loss: 1.2727 - val_accuracy: 0.5771 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "367/367 [==============================] - 4933s 13s/step - loss: 0.8487 - accuracy: 0.6942 - val_loss: 1.3127 - val_accuracy: 0.5609 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "367/367 [==============================] - 4936s 13s/step - loss: 0.8295 - accuracy: 0.7014 - val_loss: 1.2923 - val_accuracy: 0.5737 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "367/367 [==============================] - 4998s 14s/step - loss: 0.7503 - accuracy: 0.7318 - val_loss: 1.2516 - val_accuracy: 0.5876 - lr: 2.0000e-04\n",
      "Epoch 17/1000\n",
      "367/367 [==============================] - 5128s 14s/step - loss: 0.7324 - accuracy: 0.7412 - val_loss: 1.2691 - val_accuracy: 0.5834 - lr: 2.0000e-04\n",
      "Epoch 18/1000\n",
      "367/367 [==============================] - 5193s 14s/step - loss: 0.7259 - accuracy: 0.7422 - val_loss: 1.2726 - val_accuracy: 0.5834 - lr: 2.0000e-04\n",
      "Epoch 19/1000\n",
      "367/367 [==============================] - 5091s 14s/step - loss: 0.7169 - accuracy: 0.7475 - val_loss: 1.2661 - val_accuracy: 0.5909 - lr: 2.0000e-04\n",
      "Epoch 20/1000\n",
      "367/367 [==============================] - 5162s 14s/step - loss: 0.7131 - accuracy: 0.7473 - val_loss: 1.2750 - val_accuracy: 0.5832 - lr: 2.0000e-04\n",
      "Epoch 21/1000\n",
      "367/367 [==============================] - 4841s 13s/step - loss: 0.7045 - accuracy: 0.7505 - val_loss: 1.2893 - val_accuracy: 0.5832 - lr: 2.0000e-04\n",
      "Epoch 22/1000\n",
      "367/367 [==============================] - 4786s 13s/step - loss: 0.6825 - accuracy: 0.7600 - val_loss: 1.2730 - val_accuracy: 0.5830 - lr: 4.0000e-05\n",
      "Epoch 23/1000\n",
      "367/367 [==============================] - 4838s 13s/step - loss: 0.6885 - accuracy: 0.7592 - val_loss: 1.2684 - val_accuracy: 0.5852 - lr: 4.0000e-05\n",
      "Epoch 24/1000\n",
      "367/367 [==============================] - 4939s 13s/step - loss: 0.6809 - accuracy: 0.7615 - val_loss: 1.2721 - val_accuracy: 0.5825 - lr: 4.0000e-05\n",
      "Epoch 25/1000\n",
      "367/367 [==============================] - 4880s 13s/step - loss: 0.6748 - accuracy: 0.7656 - val_loss: 1.2735 - val_accuracy: 0.5858 - lr: 4.0000e-05\n",
      "Epoch 26/1000\n",
      "367/367 [==============================] - 4981s 14s/step - loss: 0.6781 - accuracy: 0.7634 - val_loss: 1.2745 - val_accuracy: 0.5864 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"art_style_recognition_final_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 567s 12s/step - loss: 1.3052 - accuracy: 0.5894\n",
      "Test accuracy: 0.5894073843955994\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jiangtianhan/Desktop/You will get good one day/TheUltimateAi/notebook/anotherModel.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jiangtianhan/Desktop/You%20will%20get%20good%20one%20day/TheUltimateAi/notebook/anotherModel.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(test_ds)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiangtianhan/Desktop/You%20will%20get%20good%20one%20day/TheUltimateAi/notebook/anotherModel.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m top5_classes \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mtop_k(test_predictions, k\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\u001b[39m.\u001b[39mindices\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiangtianhan/Desktop/You%20will%20get%20good%20one%20day/TheUltimateAi/notebook/anotherModel.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m top5_probilities \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mtop_k(test_predictions, k\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\u001b[39m.\u001b[39mvalues\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(test_ds)\n",
    "\n",
    "top5_classes = tf.math.top_k(test_predictions, k=5).indices\n",
    "top5_probilities = tf.math.top_k(test_predictions, k=5).values\n",
    "\n",
    "print(\"Top 5 classes for the first image:\", top5_classes[0].numpy())\n",
    "print(\"Probabilities for the top 5 classes for the first image:\", top5_probilities[0].numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
