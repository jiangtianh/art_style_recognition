{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, applications\n",
    "\n",
    "# Note : we are using TensorFlow Core v2.5.0, in TensorFlow Core v2.6.0 all the data \n",
    "# augmentation layers are part of tf.keras.layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomZoom\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"../raw_data/wikiart/wikiart-target_style-class_14-keepgenre_True-merge_style_m1-flat_False/train\"\n",
    "VAL_DIR = \"../raw_data/wikiart/wikiart-target_style-class_14-keepgenre_True-merge_style_m1-flat_False/val\"\n",
    "TEST_DIR = \"../raw_data/wikiart/wikiart-target_style-class_14-keepgenre_True-merge_style_m1-flat_False/test\"\n",
    "\n",
    "BATCH_SIZE = 128 # Hyper param, you can tune it\n",
    "EPOCHS = 1000 # Large number, early stopping to stop training before this number\n",
    "IMG_HEIGHT = 224 # VGG's dim\n",
    "IMG_WIDTH = 224 # VGG's dim\n",
    "NUM_CLASSES = 14 # Number of art styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46971 files belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=TRAIN_DIR,\n",
    "    labels='inferred',\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "assert len(train_ds.class_names) == NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5871 files belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=VAL_DIR,\n",
    "    labels='inferred',\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "assert len(val_ds.class_names) == NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5872 files belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=TEST_DIR,\n",
    "    labels='inferred',\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "assert len(test_ds.class_names) == NUM_CLASSES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_images_count = (int(len(list(train_ds)))+int(len(list(val_ds)))+int(len(list(test_ds))))*BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58752"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_images_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Optimizing the dataset by caching and prefetching the data\n",
    "train_ds = train_ds.cache().shuffle(int(total_images_count)).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_model = applications.VGG16(\n",
    "    include_top=False, # We do not include VGG classification layers\n",
    "    weights='imagenet', # We import VGG pre-trained on ImageNet\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), \n",
    "    classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layer_model.trainable = False # We do not train VGG weights\n",
    "\n",
    "# layer_model.layers[-2:] # Set the two last layers as trainable\n",
    "# for layer in layer_model.layers[-4:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "trainable_layer_count = 0\n",
    "for i in range(len(layer_model.layers)):\n",
    "    if layer_model.layers[i].trainable:\n",
    "        trainable_layer_count += 1\n",
    "\n",
    "layer_model.trainable = True\n",
    "\n",
    "trainable_layer_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation_layers = tf.keras.models.Sequential([\n",
    "    RandomFlip(\"horizontal\", input_shape=(224, 224, 3)),\n",
    "    RandomRotation(0.3),\n",
    "    RandomZoom(0.3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "x = data_augmentation_layers(inputs)\n",
    "\n",
    "x = applications.vgg16.preprocess_input(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = layers.Dense(NUM_CLASSES, activation='softmax', name=\"classification_layer\")(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=10, mode='min', restore_best_weights=True)\n",
    "\n",
    "# You can add it to the callbacks if you want to save checkpoints\n",
    "checkpoint_dir = \"../VGG16/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + f\"-unfreeze_{trainable_layer_count}\"\n",
    "mcp = ModelCheckpoint(\n",
    "    filepath=checkpoint_dir,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_freq=10,\n",
    "    save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "recorded_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") \n",
    "log_dir = f\"../VGG16/\" + \\\n",
    "    recorded_time + \\\n",
    "    f\"-images_{total_images_count}\" + \\\n",
    "    f\"-unfreeze_{trainable_layer_count}\" + \\\n",
    "    f\"-batch_{BATCH_SIZE}\"\n",
    "\n",
    "tsboard = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangtianhan/Desktop/You will get good one day/TheUltimateAi/notebook/.venv/lib/python3.11/site-packages/keras/src/backend.py:5562: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "2023-10-11 10:39:38.280500: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 12 of 58752\n",
      "2023-10-11 10:39:48.548006: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 32 of 58752\n",
      "2023-10-11 10:39:58.434776: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 52 of 58752\n",
      "2023-10-11 10:40:08.177018: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 71 of 58752\n",
      "2023-10-11 10:40:18.343187: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 92 of 58752\n",
      "2023-10-11 10:40:28.787610: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 112 of 58752\n",
      "2023-10-11 10:40:38.154059: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 131 of 58752\n",
      "2023-10-11 10:40:48.605910: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 149 of 58752\n",
      "2023-10-11 10:40:58.153116: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 167 of 58752\n",
      "2023-10-11 10:41:08.161424: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 185 of 58752\n",
      "2023-10-11 10:41:18.527461: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 206 of 58752\n",
      "2023-10-11 10:41:28.419341: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 225 of 58752\n",
      "2023-10-11 10:41:38.184631: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 243 of 58752\n",
      "2023-10-11 10:41:48.372235: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 264 of 58752\n",
      "2023-10-11 10:41:58.613818: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 286 of 58752\n",
      "2023-10-11 10:42:08.551121: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 305 of 58752\n",
      "2023-10-11 10:42:18.358076: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 325 of 58752\n",
      "2023-10-11 10:42:28.381248: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 345 of 58752\n",
      "2023-10-11 10:42:36.012688: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 288s 273ms/step - loss: 37.4860 - accuracy: 0.1015 - val_loss: 18.7871 - val_accuracy: 0.0330\n",
      "Epoch 2/1000\n",
      "367/367 [==============================] - 88s 238ms/step - loss: 21.2460 - accuracy: 0.1359 - val_loss: 7.6009 - val_accuracy: 0.1042\n",
      "Epoch 3/1000\n",
      "367/367 [==============================] - 86s 235ms/step - loss: 9.6869 - accuracy: 0.1655 - val_loss: 3.2438 - val_accuracy: 0.2076\n",
      "Epoch 4/1000\n",
      "367/367 [==============================] - 92s 251ms/step - loss: 3.0515 - accuracy: 0.2558 - val_loss: 2.2449 - val_accuracy: 0.3018\n",
      "Epoch 5/1000\n",
      "367/367 [==============================] - 93s 252ms/step - loss: 2.2211 - accuracy: 0.2949 - val_loss: 2.1897 - val_accuracy: 0.2843\n",
      "Epoch 6/1000\n",
      "367/367 [==============================] - 100s 273ms/step - loss: 2.1785 - accuracy: 0.2926 - val_loss: 2.1562 - val_accuracy: 0.2916\n",
      "Epoch 7/1000\n",
      "367/367 [==============================] - 101s 275ms/step - loss: 2.1524 - accuracy: 0.2927 - val_loss: 2.1372 - val_accuracy: 0.2839\n",
      "Epoch 8/1000\n",
      "367/367 [==============================] - 98s 266ms/step - loss: 2.1393 - accuracy: 0.2904 - val_loss: 2.1266 - val_accuracy: 0.2839\n",
      "Epoch 9/1000\n",
      "367/367 [==============================] - 99s 269ms/step - loss: 2.1310 - accuracy: 0.2912 - val_loss: 2.1233 - val_accuracy: 0.2896\n",
      "Epoch 10/1000\n",
      "367/367 [==============================] - 97s 265ms/step - loss: 2.1297 - accuracy: 0.2899 - val_loss: 2.1207 - val_accuracy: 0.2838\n",
      "Epoch 11/1000\n",
      "367/367 [==============================] - 96s 261ms/step - loss: 2.1253 - accuracy: 0.2899 - val_loss: 2.1158 - val_accuracy: 0.2841\n",
      "Epoch 12/1000\n",
      "367/367 [==============================] - 95s 258ms/step - loss: 2.1244 - accuracy: 0.2901 - val_loss: 2.1171 - val_accuracy: 0.2909\n",
      "Epoch 13/1000\n",
      "367/367 [==============================] - 102s 278ms/step - loss: 2.1233 - accuracy: 0.2909 - val_loss: 2.1138 - val_accuracy: 0.2839\n",
      "Epoch 14/1000\n",
      "367/367 [==============================] - 95s 257ms/step - loss: 2.1211 - accuracy: 0.2922 - val_loss: 2.1151 - val_accuracy: 0.2843\n",
      "Epoch 15/1000\n",
      "367/367 [==============================] - 94s 257ms/step - loss: 2.1209 - accuracy: 0.2915 - val_loss: 2.1139 - val_accuracy: 0.2838\n",
      "Epoch 16/1000\n",
      "367/367 [==============================] - 91s 246ms/step - loss: 2.1220 - accuracy: 0.2901 - val_loss: 2.1157 - val_accuracy: 0.2836\n",
      "Epoch 17/1000\n",
      "367/367 [==============================] - 92s 251ms/step - loss: 2.1214 - accuracy: 0.2908 - val_loss: 2.1127 - val_accuracy: 0.2839\n",
      "Epoch 18/1000\n",
      "367/367 [==============================] - 93s 254ms/step - loss: 2.1215 - accuracy: 0.2903 - val_loss: 2.1150 - val_accuracy: 0.2906\n",
      "Epoch 19/1000\n",
      "367/367 [==============================] - 95s 258ms/step - loss: 2.1210 - accuracy: 0.2904 - val_loss: 2.1168 - val_accuracy: 0.2860\n",
      "Epoch 20/1000\n",
      "367/367 [==============================] - 98s 267ms/step - loss: 2.1221 - accuracy: 0.2905 - val_loss: 2.1167 - val_accuracy: 0.2904\n",
      "Epoch 21/1000\n",
      "367/367 [==============================] - 96s 262ms/step - loss: 2.1216 - accuracy: 0.2918 - val_loss: 2.1184 - val_accuracy: 0.2838\n",
      "Epoch 22/1000\n",
      "367/367 [==============================] - 92s 251ms/step - loss: 2.1215 - accuracy: 0.2899 - val_loss: 2.1162 - val_accuracy: 0.2836\n",
      "Epoch 23/1000\n",
      "367/367 [==============================] - 95s 260ms/step - loss: 2.1201 - accuracy: 0.2902 - val_loss: 2.1129 - val_accuracy: 0.2838\n",
      "Epoch 24/1000\n",
      "367/367 [==============================] - 95s 257ms/step - loss: 2.1225 - accuracy: 0.2899 - val_loss: 2.1142 - val_accuracy: 0.2838\n",
      "Epoch 25/1000\n",
      "367/367 [==============================] - 95s 259ms/step - loss: 2.1195 - accuracy: 0.2915 - val_loss: 2.1123 - val_accuracy: 0.2919\n",
      "Epoch 26/1000\n",
      "367/367 [==============================] - 94s 258ms/step - loss: 2.1207 - accuracy: 0.2906 - val_loss: 2.1118 - val_accuracy: 0.2856\n",
      "Epoch 27/1000\n",
      "367/367 [==============================] - 92s 251ms/step - loss: 2.1212 - accuracy: 0.2901 - val_loss: 2.1117 - val_accuracy: 0.2838\n",
      "Epoch 28/1000\n",
      "367/367 [==============================] - 91s 247ms/step - loss: 2.1219 - accuracy: 0.2900 - val_loss: 2.1134 - val_accuracy: 0.2838\n",
      "Epoch 29/1000\n",
      "367/367 [==============================] - 97s 265ms/step - loss: 2.1198 - accuracy: 0.2910 - val_loss: 2.1121 - val_accuracy: 0.2943\n",
      "Epoch 30/1000\n",
      "367/367 [==============================] - 91s 247ms/step - loss: 2.1226 - accuracy: 0.2904 - val_loss: 2.1153 - val_accuracy: 0.2838\n",
      "Epoch 31/1000\n",
      "367/367 [==============================] - 91s 249ms/step - loss: 2.1209 - accuracy: 0.2893 - val_loss: 2.1118 - val_accuracy: 0.2839\n",
      "Epoch 32/1000\n",
      "367/367 [==============================] - 92s 252ms/step - loss: 2.1216 - accuracy: 0.2903 - val_loss: 2.1115 - val_accuracy: 0.2836\n",
      "Epoch 33/1000\n",
      "367/367 [==============================] - 93s 254ms/step - loss: 2.1219 - accuracy: 0.2903 - val_loss: 2.1139 - val_accuracy: 0.2838\n",
      "Epoch 34/1000\n",
      "367/367 [==============================] - 92s 251ms/step - loss: 2.1214 - accuracy: 0.2894 - val_loss: 2.1127 - val_accuracy: 0.2868\n",
      "Epoch 35/1000\n",
      "367/367 [==============================] - 91s 247ms/step - loss: 2.1217 - accuracy: 0.2903 - val_loss: 2.1120 - val_accuracy: 0.2838\n",
      "Epoch 36/1000\n",
      "367/367 [==============================] - 93s 253ms/step - loss: 2.1210 - accuracy: 0.2914 - val_loss: 2.1140 - val_accuracy: 0.2838\n",
      "Epoch 37/1000\n",
      "367/367 [==============================] - 92s 251ms/step - loss: 2.1195 - accuracy: 0.2914 - val_loss: 2.1131 - val_accuracy: 0.2860\n",
      "Epoch 38/1000\n",
      "367/367 [==============================] - 93s 254ms/step - loss: 2.1213 - accuracy: 0.2903 - val_loss: 2.1158 - val_accuracy: 0.2880\n",
      "Epoch 39/1000\n",
      "367/367 [==============================] - 91s 248ms/step - loss: 2.1205 - accuracy: 0.2897 - val_loss: 2.1111 - val_accuracy: 0.2841\n",
      "Epoch 40/1000\n",
      "367/367 [==============================] - 93s 252ms/step - loss: 2.1211 - accuracy: 0.2908 - val_loss: 2.1156 - val_accuracy: 0.2839\n",
      "Epoch 41/1000\n",
      "367/367 [==============================] - 92s 251ms/step - loss: 2.1199 - accuracy: 0.2904 - val_loss: 2.1129 - val_accuracy: 0.2860\n",
      "Epoch 42/1000\n",
      "367/367 [==============================] - 99s 271ms/step - loss: 2.1223 - accuracy: 0.2900 - val_loss: 2.1163 - val_accuracy: 0.2838\n",
      "Epoch 43/1000\n",
      "367/367 [==============================] - 96s 262ms/step - loss: 2.1223 - accuracy: 0.2898 - val_loss: 2.1136 - val_accuracy: 0.2902\n",
      "Epoch 44/1000\n",
      "367/367 [==============================] - 90s 246ms/step - loss: 2.1204 - accuracy: 0.2916 - val_loss: 2.1130 - val_accuracy: 0.2839\n",
      "Epoch 45/1000\n",
      "367/367 [==============================] - 96s 261ms/step - loss: 2.1218 - accuracy: 0.2892 - val_loss: 2.1129 - val_accuracy: 0.2838\n",
      "Epoch 46/1000\n",
      "367/367 [==============================] - 98s 266ms/step - loss: 2.1210 - accuracy: 0.2892 - val_loss: 2.1128 - val_accuracy: 0.2839\n",
      "Epoch 47/1000\n",
      "367/367 [==============================] - 96s 262ms/step - loss: 2.1211 - accuracy: 0.2901 - val_loss: 2.1160 - val_accuracy: 0.2838\n",
      "Epoch 48/1000\n",
      "367/367 [==============================] - 91s 248ms/step - loss: 2.1213 - accuracy: 0.2903 - val_loss: 2.1122 - val_accuracy: 0.2838\n",
      "Epoch 49/1000\n",
      "367/367 [==============================] - 91s 248ms/step - loss: 2.1204 - accuracy: 0.2895 - val_loss: 2.1179 - val_accuracy: 0.2850\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001), \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds, \n",
    "    epochs=EPOCHS, \n",
    "    validation_data=val_ds, \n",
    "    callbacks=[es, tsboard], \n",
    "    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 24s 417ms/step - loss: 2.1076 - accuracy: 0.2835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.107649564743042, 0.283549040555954]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds, callbacks=tsboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangtianhan/Desktop/You will get good one day/TheUltimateAi/notebook/.venv/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
